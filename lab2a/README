
INCLUDED FILES:
	lab2_add.c: source file that implements the adding function
	lab2_list.c: source file that does updates to a linked list
	SortedList.h: header file provided by the project spec
	SortedList.c: implementation of the doubly linked list
	Makefile: supporting make build, tests, graphs, clean, dist
	lab2_add.csv: includes comma-separated values from running
		lab2_add with different options by make tests
	lab2_list.csv: includes comma-separated values from running
		lab2_list with different options by make tests
	-graphs generated by gnuplot (make graphs):
	lab2_add-1.png
	lab2_add-2.png
	lab2_add-3.png
	lab2_add-4.png
	lab2_add-5.png
	lab2_list-1.png
	lab2_list-2.png
	lab2_list-3.png
	lab2_list-4.png
	README: the current file
	lab2_add.gp: script provided by project spec for making graphs
	lab2_list.gp: script provided by project spec for making graphs
	
RESOURCES: 
	I had to refer to a few different online tutorials to get reminded
	of linked list and how to implement a doubly linked list. I also 
	wasn't sure that in the case of a circular doubly linked list,
	whether the last and first items have to point to the head or not.
	In my implementation, they do point to the head. 
	When creating and initializing the specified number of elements
	in lab2_list.c, what I did originally was to allocate a huge chunk
	of memory using a pointer to SortedListElement_t. However, I was 
	having a weird problem where the key of (only) the second element
	ended up being NULL every time I ran the executable. After hours
	of debugging I couldn't figure out what caused it so I referred to 
	this repository https://github.com/codeKaren/CS-111/blob/master/
	Lab%202/Lab%202A/lab2_list.c and also this one https://github.com/
	natasha41575/CS111/blob/master/Project2/A/lab2_list.c to see how 
	other people were implementing it. I ended up using a double pointer
	instead, and allocating enough memory for pointers to elements 
	(instead of elements themselves) then allocating enough memory 
	for a single element for each one of those pointers later on.

QUESTION 2.1.1:
	It takes many iterations before errors are seen because things have
	to go "exactly wrong" for the errors to happen and the chances of
	that happening are low; but when the number of iterations are 
	increased this small probability becomes a larger number.
	A significantly smaller number of iterations seldom fail for the
	same reason; since the number of times the operation fails is 
	equal to the number of iterations multiplied by the probability
	of failure.

QUESTION 2.1.2:
	The yield runs are a lot slower because every time a thread
	yields() to CPU, it is stopped; the context switch is time-
	consuming and the interrupt we cause creates a slow-down.
	The additional time is going to the context switch and handling
	the interrupt we caused.
	No, because we are also including the time spent on the yield
	and context switch, which makes it not be the true runtime 
	per operation. 

QUESTION 2.1.3:
	If we hold the number of threads about the same and just increase
	the number of iterations, the cost per iteration decreases because
	the largest cost is due to creating new threads while the iterations
	can be done faster.
	To get the "correct" cost, we look at the plot which shows the cost
	first decreases and then starts to become stable; the cost per
	iteration in the part of the graph where there isn't a drastic
	drop is closest to the "correct" cost.

QUESTION 2.1.4:
	The performance of all the options is similar since most of the 
	time is spent on creating threads and the option-specific actions
	don't take a significant amount of time comparint to that since
	threads won't have to wait a long time to acquire the locks.
	However, when we raise the number of threads, each one of them
	has to spend a greater amount of time waiting for the locks to
	be released and thus the runtime becomes larger.

QUESTION 2.2.1:
	The general shape of these graphs shows an initial slow increase
	and towards the end (past 8 threads) a slow decrease starts to
	happen.
	The cost per operation for mutex-protected adds is an order of 
	10 times higher than that of the sorted lists. The reason is that 
	less context switches happen.

QUESTION 2.2.2:
	The general trend of cost per operation with respect to the 
	number of threads is a slow increase until about when we have
	4-8 threads, where a slow decrease starts to happen. The increase
	is due to the overhead of creating and maintaining more threads.
	For both parts 1 and 2 the spin locks have a higher cost per
	operation (specially as the number of threads increases).
